import sys
sys.path.append('..')

import numpy as np
import pandas as pd
from typing import Union

from simulation.leukocytes import reference_axis
from utils.distributions import WrappedNormal, Uniform
from simulation.sources import Source
from inference.base import Inferer
from utils.numpy import nan_concatenate, angle_between


class BiasedPersistentInferer(Inferer):

    def __init__(self, paths: Union[pd.DataFrame, list], source: Union[Source, list]=None, priors: list=None):
        """
        Initialise an inference pipeline for biased persistent walkers.
        Pass in a set of observed paths, with a corresponding set of
        sources.

        Parameters
        ----------
        paths       A pandas DataFrame containing the x-y coordinate readings of the
                    different paths taken by migrating leukocytes. Should have at least
                    the four following columns: [trackID, time, x, y]. The units are not
                    important, as long as the distance units are compatible with the
                    source (see below). It is also possible to pass a list of different
                    paths dataframes, which have been gathered with respect to different
                    sources.

        source      a sources.Source object. This specifies the coordinates of the source
                    which generated the paths. This may be a list of sources, if a list of
                    paths dataframes are passed. They must be the same length in this case.


        """

        super().__init__()

        if source is None:
            print('WARNING: No source passed to inferer - assuming source located at (0, 0)')
            if isinstance(paths, (list, tuple)):
                source = [PointSource(position=[0, 0])] * len(paths)
            elif isinstance(paths, pd.DataFrame):
                source = PointSource(position=[0, 0])

        # perform checks on the paths and sources
        if isinstance(paths, pd.DataFrame) and isinstance(source, Source):
            paths = [paths]
            source = [source]

        else:
            assert isinstance(paths, (list, tuple)), 'Pass multiple path sets as a list'
            assert isinstance(source, (list, tuple)), 'Pass multiple sources as a list'
            assert len(paths) == len(source), 'For multiple paths and sources, pass lists of equal length for each'

        # perform prior checks
        if priors is None:
            # this is the basic uninformative prior
            self.priors = [Uniform(0, 1), Uniform(0, 1), Uniform(0, 1)]
            self.uniform_prior = True

        # get a list of alphas and betas for each set of paths
        # (these are the persistence and bias directions resp.)
        alphas = []
        betas = []
        for path_set, source in zip(paths, source):
            a, b = _get_alphas_betas(_prepare_paths(path_set), source)
            if a.shape != (0, 0) and b.shape != (0, 0):
                alphas.append(a)
                betas.append(b)

        # concantenate them into two big arrays
        alphas = nan_concatenate(alphas, axis=1)
        betas = nan_concatenate(betas, axis=1)

        # extract initial angles
        self.alpha0 = alphas[0, :]
        self.beta0 = betas[0, :]

        # seperate angles and previous angles

        # * 'alpha' refers to the current observed angle under consideration.
        # * 'beta' refers to the current angle towards the source
        # * 'alpha_' refers to the previous observed angle

        self.betas = betas[1:, :]
        self.alphas = alphas[1:, :]
        self.alphas_ = alphas[:-1, :]

    def log_likelihood(self, params: np.ndarray) -> float:
        """
        Get the log-likelihood of a set of parameters w, p, b.

        * 'alpha' refers to the current observed angle under consideration.
        * 'beta' refers to the current angle towards the source
        * 'alpha_' refers to the previous observed angle

        at any step t > 1, the probability distribution governing the observed
        angle alpha is

             p(alpha) = w * WN(alpha; beta, -2log(b)) + (1-w) * WN(alpha; alpha_, -2log(p))

        where WN(mu, sig) is a wrapped normal distribution. The log likelihood
        of observing T strings of angles 'alphas' is

            SUM_t SUM_i log[p(alpha_ti)]

        Params:

            w:         The variable w which defines the probability of taking a biased step
            p:         The variable p, defining the variance of persistent motion
            b:         The variable b, defining the variance of boased motion

        Returns:

            log_prob:  The log probability that the paths were generated by a walker
                       with parameters (w, p, b)
        """

        # params may not be out of bounds [0, 1]
        if (params > 1).any() or (params < 0).any():
            return -np.inf

        w, p, b = params
        sig_b = (-2 * np.log(b)) ** 0.5
        sig_p = (-2 * np.log(p)) ** 0.5

        # The probability of observing the first step, given the angle beta0 towards the source
        p_0 = WrappedNormal(mu=self.beta0, sig=sig_b).pdf(theta=self.alpha0)

        # biased probabilities
        p_b = WrappedNormal(mu=self.betas, sig=sig_b).pdf(theta=self.alphas)

        # persistent probabilities
        p_p = WrappedNormal(mu=self.alphas_, sig=sig_p).pdf(theta=self.alphas)

        # combined probabilities
        p_t = w * p_b + (1 - w) * p_p

        # take logs
        log_p_0 = np.log(p_0)
        log_p_t = np.log(p_t)

        # this handles for when each path has an uneven number of steps. Some values will be nan
        log_p_t[np.isnan(log_p_t)] = 0
        log_p_0[np.isnan(log_p_0)] = 0

        return log_p_0.sum() + log_p_t.sum()

    def log_prior(self, params: np.ndarray) -> float:
        """
        For a given set of parameters, calculate the log of the prior
        pdf at this value. If our prior is Uniform(0, 1) for each
        dimension, then the log prior is 0 if all params are between
        0 and 1, and -inf if any param is out of that range.

        Parameters
        ----------
        params      Numpy array of shape (3,) containing the paramater
                    values

        Returns
        -------
        a float value of the log prior at the params value

        """

        if self.uniform_prior:

            if (params > 1).any() or (params < 0).any():
                return -np.inf
            else:
                return 0

        else:
            return sum([prior.logpdf(param) for prior, param in zip(self.priors, params)])

    def infer(self,
              n_chains: int=5,
              n_steps: int=10000,
              burn_in: int=3000,
              target_ar: float=0.234,
              seed: int=0,
              suppress_warnings: bool=False,
              progress_bar: bool=True) -> np.ndarray:

        return super().infer(n_chains, n_steps, burn_in, target_ar, seed, suppress_warnings, progress_bar)

def _get_alphas_betas(paths_matrix: np.ndarray, source: Source):
    """
    Given a set of raw x-y coordinates, get a list of the alphas and betas, that is,
    the peristence and bias directions at any one time.

    Params:

        paths:     np.array - (T, 2, N) - paths of N walkers walking for T timesteps

    Returns:

        alphas:    np.array - (T-1, N): angle taken at each time step
        betas:     np.array - (T-1, N): direction to source at each time step

    """

    T, _, N = paths_matrix.shape

    if T <= 1 or N == 0:
        return np.array([]).reshape(0, 0), np.array([]).reshape(0, 0)

    moves = paths_matrix[1:, :, :] - paths_matrix[:-1, :, :]
    alphas = np.apply_along_axis(lambda move: angle_between(reference_axis, move), axis=1, arr=moves)
    directions_to_source = np.apply_along_axis(source.direction_to_source, axis=1, arr=paths_matrix)
    betas = np.apply_along_axis(lambda d: angle_between(reference_axis, d), axis=1, arr=directions_to_source)[:-1, :]

    return alphas, betas


def _prepare_paths(paths: pd.DataFrame, min_t: int=5) -> np.ndarray:
    """
    This function converts a paths dataframe, with columns 'trackId', 'x' and 'y' into
    a single array that can be used by the MCMC inference class. This output array will
    have shape (longest path, 2, number of paths). Any path that is shorter than the
    longest path will have its bottom values in this array filled with nans.

    example input

     trackID   time         x         y
         1.0    0.0  3.440113 -0.709177
         1.0    1.0  3.417252 -0.743963
         1.0    2.0  3.128609 -0.915821
         ...    ...       ...       ...

    output

       ---  ---  ---
    [ ---  ---  ---
       |    |    |
       |    |  path3
     path1  |    |--
       |  path2 ---
       |--  |   nan   ...
      ---   |   nan
      nan   |-- nan
      nan  ---  nan
      nan  nan  nan


    Parameters
    ----------
    paths           A paths dataframe, with columns 'trackId', 'x' and 'y' holding the x-y coordinates of each path

    min_t           The minimum number of steps a path should have in  order to be included in the matrix. Setting
                    this to a higher value can speed up inference a lot at the sacrifice of some accuracy, as the
                    output matrix has fewer columns.

    Returns
    -------
    paths_array     A numpy array formatting of the paths ready to be passed to the inference class. (T, 2, N)
    """

    if len(paths) == 0:
        return np.array([]).reshape((0, 2, 0))

    sub_paths = [path[['x', 'y']].values for id, path in paths.groupby('trackID') if path.shape[0] >= min_t]

    if len(sub_paths) == 0:
        return np.array([]).reshape((0, 2, 0))

    max_t = max(sub_paths, key=lambda x: x.shape[0]).shape[0]

    paths_array = np.zeros((max_t, 2, len(sub_paths)))
    paths_array[:] = np.nan

    for i, path in enumerate(sub_paths):
        paths_array[:path.shape[0], :, i] = path

    return paths_array


if __name__ == '__main__':

    from simulation.sources import PointSource
    from utils.plotting import plot_wpb_dist, plot_paths
    import matplotlib.pyplot as plt

    # read in some collected data from a csv
    # these paths were generated using parameters w, p, b = 0.3, 0.5, 0.7
    paths1 = pd.read_csv('../data/paths1.csv')
    paths2 = pd.read_csv('../data/paths2.csv')

    # it's important to know where the source was located with regard to the x,y observations
    source1 = PointSource(position=(0, 0))
    source2 = PointSource(position=(1.5, -1.5))

    # plot the paths
    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)
    plot_paths(paths1, source1, ax1)
    plot_paths(paths2, source2, ax2)
    ax1.set_title('Source 1')
    ax2.set_title('Source 2')
    plt.show()

    # make new inferer instance
    inferer = BiasedPersistentInferer(paths=[paths1, paths2],
                                      source=[source1, source2])

    # run the inference
    dist_out = inferer.infer(n_chains=5,
                             n_steps=10000,
                             burn_in=3000,
                             target_ar=0.234)

    # plot the parameter distributions
    plt.figure()
    plot_wpb_dist(dist_out, title='Posterior distribution for $w, p, b$')